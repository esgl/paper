\documentclass[12pt,a4paper]{article}
\def\allfiles{}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{geometry}
\usepackage{indentfirst}
\usepackage{pifont}
\usepackage{ulem}
\usepackage{color}
\usepackage{algorithm} 
\usepackage{algorithmicx} 
\usepackage{algpseudocode}  
\usepackage{amsmath}  
\renewcommand{\algorithmicrequire}{\textbf{Input:}}  % Use Input in the format of Algorithm  
\renewcommand{\algorithmicensure}{\textbf{Output:}} % Use Output in the format of Algorithm  

\setlength{\parindent}{0em}
\geometry{left=2.0cm,right=2.0cm,top=2.5cm,bottom=2.5cm}

\begin{document}
\title{Reviewer of Actor-Critic}
\author{Guannan Hu}
\maketitle
\paragraph{} Methods that learn approximations to both \uline{policy and value functions} are often call \textit{\uline{actor-critic methods}}, where 'actor' is a reference to the learned policy, and 'critic' refers to the learned value function, usually a state-value function.
\bibliographystyle{plain}
\bibliography{reference}
\end{document}